<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>对话技术调研 | Huaipeng's Blog</title><meta name=keywords content><meta name=description content="1. 相关背景
1.1. 对话系统的定义
对话系统(Dialogue System，有时也称ChatBot)是人机交互技术(Human Computer Interaction, HCI)的核心领域，旨在最大限度地模仿人与人之间的对话方式，使得人类能够用更自然的方式和机器进行交流，帮助人类完成任务、获取信息、情感陪伴等。"><meta name=author content="Huaipeng Zhao"><link rel=canonical href=https://hpzhao.github.io/posts/%E5%AF%B9%E8%AF%9D%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/><link crossorigin=anonymous href=/assets/css/stylesheet.da3211e5ef867bf2b75fd5a6515cfed7195c011e8ab735694e203810a827097b.css integrity="sha256-2jIR5e+Ge/K3X9WmUVz+1xlcAR6KtzVpTiA4EKgnCXs=" rel="preload stylesheet" as=style><link rel=icon href=https://hpzhao.github.io/img/logo.gif><link rel=icon type=image/png sizes=16x16 href=https://hpzhao.github.io/img/logo.gif><link rel=icon type=image/png sizes=32x32 href=https://hpzhao.github.io/img/logo.gif><link rel=apple-touch-icon href=https://hpzhao.github.io/logo.gif><link rel=mask-icon href=https://hpzhao.github.io/logo.gif><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://hpzhao.github.io/posts/%E5%AF%B9%E8%AF%9D%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css integrity=sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js integrity=sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script>>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><meta property="og:url" content="https://hpzhao.github.io/posts/%E5%AF%B9%E8%AF%9D%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/"><meta property="og:site_name" content="Huaipeng's Blog"><meta property="og:title" content="对话技术调研"><meta property="og:description" content="1. 相关背景 1.1. 对话系统的定义 对话系统(Dialogue System，有时也称ChatBot)是人机交互技术(Human Computer Interaction, HCI)的核心领域，旨在最大限度地模仿人与人之间的对话方式，使得人类能够用更自然的方式和机器进行交流，帮助人类完成任务、获取信息、情感陪伴等。"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-21T00:51:39+08:00"><meta property="article:modified_time" content="2024-03-21T00:51:39+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="对话技术调研"><meta name=twitter:description content="1. 相关背景
1.1. 对话系统的定义
对话系统(Dialogue System，有时也称ChatBot)是人机交互技术(Human Computer Interaction, HCI)的核心领域，旨在最大限度地模仿人与人之间的对话方式，使得人类能够用更自然的方式和机器进行交流，帮助人类完成任务、获取信息、情感陪伴等。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hpzhao.github.io/posts/"},{"@type":"ListItem","position":2,"name":"对话技术调研","item":"https://hpzhao.github.io/posts/%E5%AF%B9%E8%AF%9D%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"对话技术调研","name":"对话技术调研","description":"1. 相关背景 1.1. 对话系统的定义 对话系统(Dialogue System，有时也称ChatBot)是人机交互技术(Human Computer Interaction, HCI)的核心领域，旨在最大限度地模仿人与人之间的对话方式，使得人类能够用更自然的方式和机器进行交流，帮助人类完成任务、获取信息、情感陪伴等。\n","keywords":[],"articleBody":"1. 相关背景 1.1. 对话系统的定义 对话系统(Dialogue System，有时也称ChatBot)是人机交互技术(Human Computer Interaction, HCI)的核心领域，旨在最大限度地模仿人与人之间的对话方式，使得人类能够用更自然的方式和机器进行交流，帮助人类完成任务、获取信息、情感陪伴等。\n从人机交互技术视角来看，对话机器人代表了一种新的交互范式。人机交互经历了三个阶段：\n命令行界面(CLI，Command-Line Interface)，通过文本命令让用户与计算机进行交互； 图形界面(GUI，Graphical User Interface），通过图形、文本、按钮、图标、颜色和动画等视觉元素来显示信息，让用户通过鼠标、触摸屏或其他输入设备与这些元素交互，操作计算机或移动设备； 对话界面(CUI，Conversational User Interface），通过对话进行人机交互，UI更加动态和智能 GUI和CUI的详细对比如下：\n1.2. 对话系统类型 对话系统通常分为两类：任务型对话系统(task-oriented dialogue systems, TOD)和开放域对话系统(open-domain dialogue systems, ODD)。开放域对话系统也被称为非任务型对话系统(non-task-oriented dialogue system)、闲聊机器人(chit-chat bot)或者对话机器人(chat bot)。\n任务型对话系统面向垂直领域，目的是使用尽 可能少的对话轮数帮助用户完成预定任务或动作， 例如预定机票、酒店和餐馆等。非任务型对话系统面向开放领域，要求其回复具有一致性、多样化和个性化。由于话题自由，因此 对系统的知识要求极高。\n1.3. 对话系统发展阶段 从架构差异性上来看，对话系统目前有关三个重要阶段：\n基于规则的对话系统。基于关键词模版配置的规则，代表工作有ELIZA： 基于机器学习/深度学习的对话系统。利用机器学习/深度学习大大降低了人力成本，对数据要求较高： 基于LLM Agent的对话系统。LLM具备知识、推理和生成能力，大大提高了对话质量上限： 本篇调研主要讲解基于深度学习和基于LLM Agent的对话系统。\n2. 基于深度学习的对话系统 2.1. 任务型对话系统 2.1.1. 整体架构 任务式对话系统一般包含SLU/NLU(Spoken/Natural Language Understanding)、DM(Dialogue Management)和NLG(Natural Language Generation)三个模块。其中DM又包含DST(Dialogue State Tracking)和DP(Dialogue Policy)两部分。简单来说，NLU模块负责理解用户当前对话的意图和关键信息用于后续决策，DM模块负责追踪用户当前的对话状态，并据此做出决策(例如追问、确认信息等)，NLG模块负责根据上一步的决策信息生成回复。有些对话系统将NLU和DM联合建模，还有些对话系统直接端到端建模。\n2.1.2. SLU/NLU模块 2.1.2.1. NLU任务定义 NLU包含三个任务：领域识别、意图识别和槽位识别。前两者为典型的分类任务，后者为典型的序列标注任务。\n2.1.2.2. NLU方案 三个任务可单独建模，也可以联合建模。联合建模有两种范式：\nNLU代表性方法总结如下：\n2.1.3. DST模块 2.1.3.1. 对话状态定义 对话状态(Dialogue State, DS)是一种将$t$时刻的对话表示为可供系统选择下一时刻动作信息的数据结构，可以看作每个槽值的取值分布情况。\n首先看个简单的示例，快速理解下对话状态：\nNLU和DST都会做槽位填充，不同的是NLU侧重从当前一轮对话提取槽值，而DST会考虑所有对话信息提取槽值。当然NLU和DST可以联合建模。一个完整的对话状态包含三部分：\n目标约束有关的槽位. 约束的值来自用户对话或者一些特殊值。特殊值一般包含$Dontcare$和$None$，前者表示该槽位用户不关心，后者表示用户还未指定该槽位的值。 请求槽位. 它可以是用户查询以从代理处获得答案的槽位名称列表。 当前轮次的请求方法. 它由指示交互类别的值组成。$byconstraints$表示用户试图在他的要求中指定约束信息；$byalternatives$表示用户需要一个替代实体；$finished$表明用户打算结束对话。 具体的例子如下：\n2.1.3.2. DST方案 DST以当前的动作$u_n$、前$n-1$轮的对话状态和相应的系统动作作为输入，输出其对当前对话状态$s_t$的估计。经典的DST模型为NBT(Neural Belief Tracker)，将槽值抽取变为二分类模型，大大降低了任务难度。\n其他DST方法总结如下：\n2.1.4. DP模块 2.1.4.1. DP问题定义 对话策略根据DST估计的对话状态$s_t$，通过预设的候选动作集，选择系统动作或策略$a_n$。动作可以是查询数据库、询问用户等。DP性能的优劣决定着人机对话系统的成败。DP模型可以通过监督学习、强化学习和模仿学习得到。\n监督学习需要专家手工设计对话策略规则，通过上一步生成的动作进行监督学习。由于DP的性能受特定域的特性、语音识别的鲁棒性、任务的复杂程度等影响，因此手工设计对话策略规则比较困难， 而且难以拓展到其他领域。这使得强化学习逐渐代 替专家手工设计一系列复杂的决策规则。另外从任务定义上看，强化学习擅长解决序列决策问题。\n2.1.4.2. DP方案 下面是一个通过DQN建模DP的方案，输入为观测到的对话语义信息和数据库，输出为系统动作。\nDP方法总结如下：\n2.1.5. NLG模块 2.1.5.1. NLG任务定义 NLG的主要任务是将DM模块输出的抽象表达转换为句法合法、语义准确的自然语言句子。一个好的应答语句应该具有上下文的连贯性、回复内容的准确性、可读性和多样性。广义的NLG还包含生成GUI，给定可选的交互对话动作。\n2.1.5.2. NLG方案 NLG的方法可以划分为：基于规则模板/句子规划的方法、基于语言模型的方法和基于深度学习的方法。\n基于规则的方法示例如下：\n基于深度学习的示例如下：\nNLG的方法汇总如下：\n2.1.6. 端到端的任务式对话系统 2.1.6.1. Pipeline方法缺点 Pipeline方法一般分别建立NLU、DM和NLG等模块，这些子模块通常还要分解为更小的子任务分别建模，然后按照顺序将这些模块连接起来。这种方法简单清楚，各个模块任务明确，并且可以分开研究，各自解决各自的问题。\n但是Pipeline方法的问题也很明显:\n领域相关性强。针对每个领域都需要人工设计语义槽、动作空间和决策，导致系统的设计和领域非常相关，难以扩展到新的领域。 模块之间独立。各个模块之间相互独立，需要为每个模块提供大量的领域相关的标注数据。 模块处理相互依赖。上游模块的错误会级联到下游模块，下游模块的反馈难以传到上游模块，使其很难识别错误来源。例如DM的决策出现错误，其原因可能是语言理解发生了错误，也可能是语音识别的错误。并且，由于一个模块的输入依赖于另一个模块的输出，当将一个模块调整到新环境或更新数据，其他所有模块为保证全局最优要进行相对调整。语义槽和特征也可能发生相应改变，而这个过程需要耗费大量的人力。 2.1.6.2. 端到端方法 NLU和DM的端到端建模示例：DM建模成隐藏状态，将NLU任务和DM任务联合训练，对两个任务都有提升。\n整个对话系统端到端建模示例：\n端到端方法汇总如下：\n2.1.7. 对话系统评估 任务式对话整体衡量可以用任务达成率和对话轮次指标，达成率越高越好，用的对话轮次越小越好。每个模块的评估方法如下：\n2.2. 开放域对话系统 开放域对话系统旨在与用户进行无特定任务和领域限制的闲聊（Ritter等人，2011），通常是完全数据驱动的。开放域对话系统大致可以分为三类：生成式系统(generative systems)、检索式系统(retrieval-based systems)和集成式系统(ensemble systems)。\n生成式系统应用sequence-to-sequence模型，将用户信息和对话历史映射为可能未出现在训练语料库中的响应序列。相比之下，检索式系统尝试从某个确定的响应集中找到一个预先存在的响应。集成式系统结合了生成方法和检索方法，有两种方式：可以将检索到的响应与生成的响应相比较，从中选择最佳者；生成模型也可以用来优化检索到的响应。\n生成式系统能够产生灵活的、与对话上下文相关的响应，但有时它们缺乏连贯性，倾向于生成单调的响应。检索式系统从人类响应集中选取响应，因此能够在表面水平的语言上实现更好的连贯性。然而，检索系统受限于响应集的有限性，有时检索到的响应与对话上下文的相关性较弱。\n3. 基于LLM的对话系统 3.1. 基于DL的TOD难点 基于深度学习的任务式对话系统有以下几个发展方向：\n低资源启动。任务型对话系统的成果往往依赖于大量高质量的语料作为训练数据，然而对话数据通常是异构的。例如聊天数据很多，但面向任务的对话数据集非常小。特定领域的对话数据的收集和标注是需要耗费大量的人力。 域适应能力。如何以更低的开发成本覆盖更多的领域和场景是任务型对话系统的关键问题之一，快速更新对话 智能体以处理不断变化的环境非常重要。目前的任务型对话系统针对每一个领域都需要手工制定模板导致领域拓展性不足。 领域知识和常识的引入。在深度学习框架中融合语言理解能力和推理能力的重要方法是引入领域知识和常识，因为真实人与人之间的交互需要相关领域的知识储备，仅仅依靠对话文本包含的信息无法准确地理解用户输入和恰当地回复用户。而在实际对话中，还需要对信息进行推理并回答，常识知识的引入可以使得对话系统对于用户的话语更深入的理解，从而更贴近真实人类和谐、自然的交互方式。 以下面的多领域DST为例，需要常识和推理才能正确识别槽位。\n而大模型具有知识、推理、生成的能力，并且启动资源低，不需要标注大量对话数据，天然适合建模对话式任务。\n3.2. 基于LLM增强的对话系统 3.2.1. 整体架构 该架构主要在传统搜推架构的基础上，使用LLM增强其中关键模块。\n3.2.2. NLU模块 3.2.2.1. 直接使用LLM 意图类别较少时，可以直接使用大模型做意图识别等NLU相关任务。\n3.2.2.2. LLM+传统模型 当意图类别较多时，可以先使用传统模型召回少量意图，再使用LLM判断最匹配的意图。\n3.2.2.3. LLM蒸馏传统模型 3.2.3. NLG模块 3.2.3.1. 利用LLM构造FAQ知识库 离线利用LLM构造FAQ知识库，在线通过Q2Q召回QA Pair，将Answer作为结果直接返回给用户\n3.3. 基于LLM Agent的对话系统 3.3.1. 整体架构 3.3.2. Agent模块 3.3.2.1. Single Agent 类似autoGPT，通过self-ask和react控制对话流程\n显式的对话收敛干预机制\n3.3.2.2. Multi Agent 优酷在设计上可分为主持人Agent和角色Agent两类Agent，主持人Agent的主要目的是在全局层面进行对话的管理、决定角色Agent的调用。\n3.3.3. RAG模块 3.3.3.1. KV检索 构造结构化知识库，通过KV检索相关知识\n3.3.3.2. Q2Q检索 对结果的正确性有较高要求的知识，需要先离线构造FAQ知识库，在线时计算Query和Query的相似度，选择相似度最高的QA Pair，将Answer作为知识输入到LLM\n3.3.3.3. Q2A检索 泛主题、长文本知识（影视剧情、商品详情）可以先划分为多个chunks，在线计算Query和chunk的相似度检索知识\n4. 参考文献 Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey Deep Learning for Dialogue Systems 任务型对话系统研究综述 对话系统技术 阿里小蜜技术实践-海青 An End-to-End Trainable Neural Network Model with Belief Tracking for Task-Oriented Dialog ELIZA – A Computer Program For the Study of Natural Language Communication Between Man And Machine Neural Belief Tracker: Data-Driven Dialogue State Tracking End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager A Network-based End-to-End Trainable Task-oriented Dialogue System ","wordCount":"4528","inLanguage":"en","datePublished":"2024-03-21T00:51:39+08:00","dateModified":"2024-03-21T00:51:39+08:00","author":[{"@type":"Person","name":"Huaipeng Zhao"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://hpzhao.github.io/posts/%E5%AF%B9%E8%AF%9D%E6%8A%80%E6%9C%AF%E8%B0%83%E7%A0%94/"},"publisher":{"@type":"Organization","name":"Huaipeng's Blog","logo":{"@type":"ImageObject","url":"https://hpzhao.github.io/img/logo.gif"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://hpzhao.github.io/ accesskey=h title="Huaipeng's Blog (Alt + H)">Huaipeng's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hpzhao.github.io/ title=Posts><span>Posts</span></a></li><li><a href=https://hpzhao.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://hpzhao.github.io/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://hpzhao.github.io/tags title=Tags><span>Tags</span></a></li><li><a href=https://hpzhao.github.io/about title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hpzhao.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://hpzhao.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">对话技术调研</h1><div class=post-meta><span title='2024-03-21 00:51:39 +0800 +0800'>2024-03-21</span>&nbsp;·&nbsp;<span>10 min</span>&nbsp;·&nbsp;<span>Huaipeng Zhao</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-%e7%9b%b8%e5%85%b3%e8%83%8c%e6%99%af aria-label="1. 相关背景">1. 相关背景</a><ul><li><a href=#11-%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f%e7%9a%84%e5%ae%9a%e4%b9%89 aria-label="1.1. 对话系统的定义">1.1. 对话系统的定义</a></li><li><a href=#12-%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f%e7%b1%bb%e5%9e%8b aria-label="1.2. 对话系统类型">1.2. 对话系统类型</a></li><li><a href=#13-%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f%e5%8f%91%e5%b1%95%e9%98%b6%e6%ae%b5 aria-label="1.3. 对话系统发展阶段">1.3. 对话系统发展阶段</a></li></ul></li><li><a href=#2-%e5%9f%ba%e4%ba%8e%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e7%9a%84%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f aria-label="2. 基于深度学习的对话系统">2. 基于深度学习的对话系统</a><ul><li><a href=#21-%e4%bb%bb%e5%8a%a1%e5%9e%8b%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f aria-label="2.1. 任务型对话系统">2.1. 任务型对话系统</a><ul><li><a href=#211-%e6%95%b4%e4%bd%93%e6%9e%b6%e6%9e%84 aria-label="2.1.1. 整体架构">2.1.1. 整体架构</a></li><li><a href=#212-slunlu%e6%a8%a1%e5%9d%97 aria-label="2.1.2. SLU/NLU模块">2.1.2. SLU/NLU模块</a><ul><li><a href=#2121-nlu%e4%bb%bb%e5%8a%a1%e5%ae%9a%e4%b9%89 aria-label="2.1.2.1. NLU任务定义">2.1.2.1. NLU任务定义</a></li><li><a href=#2122-nlu%e6%96%b9%e6%a1%88 aria-label="2.1.2.2. NLU方案">2.1.2.2. NLU方案</a></li></ul></li><li><a href=#213-dst%e6%a8%a1%e5%9d%97 aria-label="2.1.3. DST模块">2.1.3. DST模块</a><ul><li><a href=#2131-%e5%af%b9%e8%af%9d%e7%8a%b6%e6%80%81%e5%ae%9a%e4%b9%89 aria-label="2.1.3.1. 对话状态定义">2.1.3.1. 对话状态定义</a></li><li><a href=#2132-dst%e6%96%b9%e6%a1%88 aria-label="2.1.3.2. DST方案">2.1.3.2. DST方案</a></li></ul></li><li><a href=#214-dp%e6%a8%a1%e5%9d%97 aria-label="2.1.4. DP模块">2.1.4. DP模块</a><ul><li><a href=#2141-dp%e9%97%ae%e9%a2%98%e5%ae%9a%e4%b9%89 aria-label="2.1.4.1. DP问题定义">2.1.4.1. DP问题定义</a></li><li><a href=#2142-dp%e6%96%b9%e6%a1%88 aria-label="2.1.4.2. DP方案">2.1.4.2. DP方案</a></li></ul></li><li><a href=#215-nlg%e6%a8%a1%e5%9d%97 aria-label="2.1.5. NLG模块">2.1.5. NLG模块</a><ul><li><a href=#2151-nlg%e4%bb%bb%e5%8a%a1%e5%ae%9a%e4%b9%89 aria-label="2.1.5.1. NLG任务定义">2.1.5.1. NLG任务定义</a></li><li><a href=#2152-nlg%e6%96%b9%e6%a1%88 aria-label="2.1.5.2. NLG方案">2.1.5.2. NLG方案</a></li></ul></li><li><a href=#216-%e7%ab%af%e5%88%b0%e7%ab%af%e7%9a%84%e4%bb%bb%e5%8a%a1%e5%bc%8f%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f aria-label="2.1.6. 端到端的任务式对话系统">2.1.6. 端到端的任务式对话系统</a><ul><li><a href=#2161-pipeline%e6%96%b9%e6%b3%95%e7%bc%ba%e7%82%b9 aria-label="2.1.6.1. Pipeline方法缺点">2.1.6.1. Pipeline方法缺点</a></li><li><a href=#2162-%e7%ab%af%e5%88%b0%e7%ab%af%e6%96%b9%e6%b3%95 aria-label="2.1.6.2. 端到端方法">2.1.6.2. 端到端方法</a></li></ul></li><li><a href=#217-%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f%e8%af%84%e4%bc%b0 aria-label="2.1.7. 对话系统评估">2.1.7. 对话系统评估</a></li></ul></li><li><a href=#22-%e5%bc%80%e6%94%be%e5%9f%9f%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f aria-label="2.2. 开放域对话系统">2.2. 开放域对话系统</a></li></ul></li><li><a href=#3-%e5%9f%ba%e4%ba%8ellm%e7%9a%84%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f aria-label="3. 基于LLM的对话系统">3. 基于LLM的对话系统</a><ul><li><a href=#31-%e5%9f%ba%e4%ba%8edl%e7%9a%84tod%e9%9a%be%e7%82%b9 aria-label="3.1. 基于DL的TOD难点">3.1. 基于DL的TOD难点</a></li><li><a href=#32-%e5%9f%ba%e4%ba%8ellm%e5%a2%9e%e5%bc%ba%e7%9a%84%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f aria-label="3.2. 基于LLM增强的对话系统">3.2. 基于LLM增强的对话系统</a><ul><li><a href=#321-%e6%95%b4%e4%bd%93%e6%9e%b6%e6%9e%84 aria-label="3.2.1. 整体架构">3.2.1. 整体架构</a></li><li><a href=#322-nlu%e6%a8%a1%e5%9d%97 aria-label="3.2.2. NLU模块">3.2.2. NLU模块</a><ul><li><a href=#3221-%e7%9b%b4%e6%8e%a5%e4%bd%bf%e7%94%a8llm aria-label="3.2.2.1. 直接使用LLM">3.2.2.1. 直接使用LLM</a></li><li><a href=#3222-llm%e4%bc%a0%e7%bb%9f%e6%a8%a1%e5%9e%8b aria-label="3.2.2.2. LLM+传统模型">3.2.2.2. LLM+传统模型</a></li><li><a href=#3223-llm%e8%92%b8%e9%a6%8f%e4%bc%a0%e7%bb%9f%e6%a8%a1%e5%9e%8b aria-label="3.2.2.3. LLM蒸馏传统模型">3.2.2.3. LLM蒸馏传统模型</a></li></ul></li><li><a href=#323-nlg%e6%a8%a1%e5%9d%97 aria-label="3.2.3. NLG模块">3.2.3. NLG模块</a><ul><li><a href=#3231-%e5%88%a9%e7%94%a8llm%e6%9e%84%e9%80%a0faq%e7%9f%a5%e8%af%86%e5%ba%93 aria-label="3.2.3.1. 利用LLM构造FAQ知识库">3.2.3.1. 利用LLM构造FAQ知识库</a></li></ul></li></ul></li><li><a href=#33-%e5%9f%ba%e4%ba%8ellm-agent%e7%9a%84%e5%af%b9%e8%af%9d%e7%b3%bb%e7%bb%9f aria-label="3.3. 基于LLM Agent的对话系统">3.3. 基于LLM Agent的对话系统</a><ul><li><a href=#331-%e6%95%b4%e4%bd%93%e6%9e%b6%e6%9e%84 aria-label="3.3.1. 整体架构">3.3.1. 整体架构</a></li><li><a href=#332-agent%e6%a8%a1%e5%9d%97 aria-label="3.3.2. Agent模块">3.3.2. Agent模块</a><ul><li><a href=#3321-single-agent aria-label="3.3.2.1. Single Agent">3.3.2.1. Single Agent</a></li><li><a href=#3322-multi-agent aria-label="3.3.2.2. Multi Agent">3.3.2.2. Multi Agent</a></li></ul></li><li><a href=#333-rag%e6%a8%a1%e5%9d%97 aria-label="3.3.3. RAG模块">3.3.3. RAG模块</a><ul><li><a href=#3331-kv%e6%a3%80%e7%b4%a2 aria-label="3.3.3.1. KV检索">3.3.3.1. KV检索</a></li><li><a href=#3332-q2q%e6%a3%80%e7%b4%a2 aria-label="3.3.3.2. Q2Q检索">3.3.3.2. Q2Q检索</a></li><li><a href=#3333-q2a%e6%a3%80%e7%b4%a2 aria-label="3.3.3.3. Q2A检索">3.3.3.3. Q2A检索</a></li></ul></li></ul></li></ul></li><li><a href=#4-%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae aria-label="4. 参考文献">4. 参考文献</a></li></ul></div></details></div><div class=post-content><h1 id=1-相关背景>1. 相关背景<a hidden class=anchor aria-hidden=true href=#1-相关背景>#</a></h1><h2 id=11-对话系统的定义>1.1. 对话系统的定义<a hidden class=anchor aria-hidden=true href=#11-对话系统的定义>#</a></h2><p>对话系统(Dialogue System，有时也称ChatBot)是人机交互技术(Human Computer Interaction, <strong>HCI</strong>)的核心领域，旨在最大限度地模仿人与人之间的对话方式，使得人类能够用更自然的方式和机器进行交流，帮助人类完成任务、获取信息、情感陪伴等。</p><div align=center><img src=/img/1715067387520-0d18eedd-ea9c-40f2-b4d5-65bf2a3caba3.png alt=img></div><p>从人机交互技术视角来看，对话机器人代表了一种新的交互范式。人机交互经历了三个阶段：</p><ol><li>命令行界面(<strong>CLI</strong>，Command-Line Interface)，通过文本命令让用户与计算机进行交互；</li><li>图形界面(<strong>GUI</strong>，Graphical User Interface），通过图形、文本、按钮、图标、颜色和动画等视觉元素来显示信息，让用户通过鼠标、触摸屏或其他输入设备与这些元素交互，操作计算机或移动设备；</li><li>对话界面(<strong>CUI</strong>，Conversational User Interface），通过对话进行人机交互，UI更加动态和智能</li></ol><div align=center><img src=/img/1715071147720-926dc16d-6f9f-448b-ad68-569dd807613f.png alt=img width=100%></div><p>GUI和CUI的详细对比如下：</p><div align=center><img src=/img/1715071646360-804a5bb9-7245-4f38-ad5a-efda494c9327.png alt=img width=100%></div><h2 id=12-对话系统类型>1.2. 对话系统类型<a hidden class=anchor aria-hidden=true href=#12-对话系统类型>#</a></h2><p>对话系统通常分为两类：任务型对话系统(<strong>t</strong>ask-<strong>o</strong>riented <strong>d</strong>ialogue systems, <strong>TOD</strong>)和开放域对话系统(<strong>o</strong>pen-<strong>d</strong>omain <strong>d</strong>ialogue systems, <strong>ODD</strong>)。开放域对话系统也被称为非任务型对话系统(non-task-oriented dialogue system)、闲聊机器人(chit-chat bot)或者对话机器人(chat bot)。</p><p>任务型对话系统面向垂直领域，目的是使用尽 可能少的对话轮数帮助用户完成预定任务或动作， 例如预定机票、酒店和餐馆等。非任务型对话系统面向开放领域，要求其回复具有一致性、多样化和个性化。由于话题自由，因此 对系统的知识要求极高。</p><div align=center><img src=/img/1715082183156-097d9ad1-923d-424f-bcb4-ea09b1d59305.png alt=img width=100%></div><h2 id=13-对话系统发展阶段>1.3. 对话系统发展阶段<a hidden class=anchor aria-hidden=true href=#13-对话系统发展阶段>#</a></h2><p>从架构差异性上来看，对话系统目前有关三个重要阶段：</p><ol><li>基于规则的对话系统。基于关键词模版配置的规则，代表工作有<strong>ELIZA</strong>：</li></ol><div align=center><img src=/img/1715082508854-025fa6c1-ab5e-4615-a1f9-168fe98677fc.png alt=img width=100%></div><ol><li>基于机器学习/深度学习的对话系统。利用机器学习/深度学习大大降低了人力成本，对数据要求较高：</li></ol><div align=center><img src=/img/1715082825550-75493d3f-df35-44a2-a5bd-adb7da4cfe9d.png alt=img width=100%></div><ol><li>基于LLM Agent的对话系统。LLM具备知识、推理和生成能力，大大提高了对话质量上限：</li></ol><div align=center><img src=/img/1715083059097-c97173ec-ec78-4ede-a3e0-8119d9d45b85.png alt=img width=100%></div><p>本篇调研主要讲解基于深度学习和基于LLM Agent的对话系统。</p><h1 id=2-基于深度学习的对话系统>2. 基于深度学习的对话系统<a hidden class=anchor aria-hidden=true href=#2-基于深度学习的对话系统>#</a></h1><h2 id=21-任务型对话系统>2.1. 任务型对话系统<a hidden class=anchor aria-hidden=true href=#21-任务型对话系统>#</a></h2><h3 id=211-整体架构>2.1.1. 整体架构<a hidden class=anchor aria-hidden=true href=#211-整体架构>#</a></h3><div align=center><img src=/img/1715083983364-b8277ae1-b9f5-4b82-a79c-1b272b90bf59.png alt=img width=100%></div><p>任务式对话系统一般包含<strong>SLU</strong>/<strong>NLU</strong>(<strong>S</strong>poken/<strong>N</strong>atural <strong>L</strong>anguage <strong>U</strong>nderstanding)、<strong>DM</strong>(<strong>D</strong>ialogue <strong>M</strong>anagement)和<strong>NLG</strong>(<strong>N</strong>atural <strong>L</strong>anguage <strong>G</strong>eneration)三个模块。其中DM又包含<strong>DST</strong>(<strong>D</strong>ialogue <strong>S</strong>tate <strong>T</strong>racking)和<strong>DP</strong>(<strong>D</strong>ialogue <strong>P</strong>olicy)两部分。简单来说，NLU模块负责理解用户当前对话的意图和关键信息用于后续决策，DM模块负责追踪用户当前的对话状态，并据此做出决策(例如追问、确认信息等)，NLG模块负责根据上一步的决策信息生成回复。有些对话系统将NLU和DM联合建模，还有些对话系统直接端到端建模。</p><h3 id=212-slunlu模块>2.1.2. SLU/NLU模块<a hidden class=anchor aria-hidden=true href=#212-slunlu模块>#</a></h3><h4 id=2121-nlu任务定义>2.1.2.1. NLU任务定义<a hidden class=anchor aria-hidden=true href=#2121-nlu任务定义>#</a></h4><p>NLU包含三个任务：领域识别、意图识别和槽位识别。前两者为典型的分类任务，后者为典型的序列标注任务。</p><div align=center><img src=/img/1715084803376-54678da9-dbb8-43c8-b523-dc0c3c627f90.png alt=img width=100%></div><h4 id=2122-nlu方案>2.1.2.2. NLU方案<a hidden class=anchor aria-hidden=true href=#2122-nlu方案>#</a></h4><p>三个任务可单独建模，也可以联合建模。联合建模有两种范式：</p><div align=center><img src=/img/1715085596392-ed80009d-8718-4dde-9ce3-de46c540d044.png alt=img width=100%></div><p>NLU代表性方法总结如下：</p><div align=center><img src=/img/1715085251612-c14e69e5-e510-470f-b1b8-a91c3eaf0973.png alt=img width=100%></div><h3 id=213-dst模块>2.1.3. DST模块<a hidden class=anchor aria-hidden=true href=#213-dst模块>#</a></h3><h4 id=2131-对话状态定义>2.1.3.1. 对话状态定义<a hidden class=anchor aria-hidden=true href=#2131-对话状态定义>#</a></h4><p>对话状态(<strong>D</strong>ialogue <strong>S</strong>tate, <strong>DS</strong>)是一种将$t$时刻的对话表示为可供系统选择下一时刻动作信息的<strong>数据结构</strong>，可以看作<strong>每个槽值的取值分布情况</strong>。</p><p>首先看个简单的示例，快速理解下对话状态：</p><div align=center><img src=/img/1715154841592-415f6601-f9e2-479e-a2a4-9e415e1f6c94.png alt=img width=100%></div><p>NLU和DST都会做槽位填充，不同的是NLU侧重从当前一轮对话提取槽值，而DST会考虑所有对话信息提取槽值。当然NLU和DST可以联合建模。一个完整的对话状态包含三部分：</p><ul><li><strong>目标约束有关的槽位</strong>. 约束的值来自用户对话或者一些特殊值。特殊值一般包含$Dontcare$和$None$，前者表示该槽位用户不关心，后者表示用户还未指定该槽位的值。</li><li><strong>请求槽位</strong>. 它可以是用户查询以从代理处获得答案的槽位名称列表。</li><li><strong>当前轮次的请求方法</strong>. 它由指示交互类别的值组成。$byconstraints$表示用户试图在他的要求中指定约束信息；$byalternatives$表示用户需要一个替代实体；$finished$表明用户打算结束对话。</li></ul><p>具体的例子如下：</p><div align=center><img src=/img/1715164002564-aea0ba3a-503b-4062-917e-803ccbb84bcf.png alt=img width=100%></div><h4 id=2132-dst方案>2.1.3.2. DST方案<a hidden class=anchor aria-hidden=true href=#2132-dst方案>#</a></h4><p>DST以当前的动作$u_n$、前$n-1$轮的对话状态和相应的系统动作作为输入，输出其对当前对话状态$s_t$的估计。经典的DST模型为NBT(Neural Belief Tracker)，将槽值抽取变为二分类模型，大大降低了任务难度。</p><div align=center><img src=/img/1715165062999-d23b660c-ebb3-488e-aab2-8f709034fd43.png alt=img width=100%></div><p>其他DST方法总结如下：</p><div align=center><img src=/img/1715164767953-d747fb2a-e297-4d4d-89e7-462593ed1961.png alt=img width=100%></div><h3 id=214-dp模块>2.1.4. DP模块<a hidden class=anchor aria-hidden=true href=#214-dp模块>#</a></h3><h4 id=2141-dp问题定义>2.1.4.1. DP问题定义<a hidden class=anchor aria-hidden=true href=#2141-dp问题定义>#</a></h4><p>对话策略根据DST估计的对话状态$s_t$，通过预设的候选动作集，选择系统动作或策略$a_n$。动作可以是查询数据库、询问用户等。DP性能的优劣决定着人机对话系统的成败。DP模型可以通过监督学习、强化学习和模仿学习得到。</p><p>监督学习需要专家手工设计对话策略规则，通过上一步生成的动作进行监督学习。由于DP的性能受特定域的特性、语音识别的鲁棒性、任务的复杂程度等影响，因此手工设计对话策略规则比较困难， 而且难以拓展到其他领域。这使得强化学习逐渐代 替专家手工设计一系列复杂的决策规则。另外从任务定义上看，强化学习擅长解决序列决策问题。</p><div align=center><img src=/img/1715166363755-34ba38bc-2457-4271-babd-3afd7865ac99.png alt=img width=100%></div><h4 id=2142-dp方案>2.1.4.2. DP方案<a hidden class=anchor aria-hidden=true href=#2142-dp方案>#</a></h4><p>下面是一个通过DQN建模DP的方案，输入为观测到的对话语义信息和数据库，输出为系统动作。</p><div align=center><img src=/img/1715166523595-7e5da053-3545-4507-853f-5c7822115b4e.png alt=img width=100%></div><p>DP方法总结如下：</p><div align=center><img src=/img/1715166701432-29d3e285-6c4a-4a34-9b5b-9c9eb2c90700.png alt=img width=100%></div><h3 id=215-nlg模块>2.1.5. NLG模块<a hidden class=anchor aria-hidden=true href=#215-nlg模块>#</a></h3><h4 id=2151-nlg任务定义>2.1.5.1. NLG任务定义<a hidden class=anchor aria-hidden=true href=#2151-nlg任务定义>#</a></h4><p>NLG的主要任务是将DM模块输出的抽象表达转换为句法合法、语义准确的自然语言句子。一个好的应答语句应该具有上下文的连贯性、回复内容的准确性、可读性和多样性。广义的NLG还包含生成GUI，给定可选的交互对话动作。</p><div align=center><img src=/img/1715223873201-461a6351-d3c4-48bb-b684-04dab6948587.png alt=img width=100%></div><h4 id=2152-nlg方案>2.1.5.2. NLG方案<a hidden class=anchor aria-hidden=true href=#2152-nlg方案>#</a></h4><p>NLG的方法可以划分为：基于规则模板/句子规划的方法、基于语言模型的方法和基于深度学习的方法。</p><p>基于规则的方法示例如下：</p><div align=center><img src=/img/1715224673669-710b65e4-d88d-494d-a35c-d6e837e6cf80.png alt=img width=100%></div><p>基于深度学习的示例如下：</p><div align=center><img src=/img/1715224937950-3102ebeb-ef47-4a72-93de-857256db270c.png alt=img width=100%></div><p>NLG的方法汇总如下：</p><div align=center><img src=/img/1715223939759-6f93b619-93d8-4041-b960-4d8bffea8c57.png alt=img width=100%></div><h3 id=216-端到端的任务式对话系统>2.1.6. 端到端的任务式对话系统<a hidden class=anchor aria-hidden=true href=#216-端到端的任务式对话系统>#</a></h3><h4 id=2161-pipeline方法缺点>2.1.6.1. Pipeline方法缺点<a hidden class=anchor aria-hidden=true href=#2161-pipeline方法缺点>#</a></h4><p>Pipeline方法一般分别建立NLU、DM和NLG等模块，这些子模块通常还要分解为更小的子任务分别建模，然后按照顺序将这些模块连接起来。这种方法简单清楚，各个模块任务明确，并且可以分开研究，各自解决各自的问题。</p><p>但是Pipeline方法的问题也很明显:</p><ol><li><strong>领域相关性强</strong>。针对每个领域都需要人工设计语义槽、动作空间和决策，导致系统的设计和领域非常相关，难以扩展到新的领域。</li><li><strong>模块之间独立</strong>。各个模块之间相互独立，需要为每个模块提供大量的领域相关的标注数据。</li><li><strong>模块处理相互依赖</strong>。<strong>上游模块的错误会级联到下游模块，下游模块的反馈难以传到上游模块，使其很难识别错误来源</strong>。例如DM的决策出现错误，其原因可能是语言理解发生了错误，也可能是语音识别的错误。并且，由于一个模块的输入依赖于另一个模块的输出，当将一个模块调整到新环境或更新数据，其他所有模块为保证全局最优要进行相对调整。语义槽和特征也可能发生相应改变，而这个过程需要耗费大量的人力。</li></ol><h4 id=2162-端到端方法>2.1.6.2. 端到端方法<a hidden class=anchor aria-hidden=true href=#2162-端到端方法>#</a></h4><p>NLU和DM的端到端建模示例：DM建模成隐藏状态，将NLU任务和DM任务联合训练，对两个任务都有提升。</p><div align=center><img src=/img/1715225658990-27260d89-36fb-45ea-9e2d-b9abbb7c3292.png alt=img width=100%></div><p>整个对话系统端到端建模示例：</p><div align=center><img src=/img/1715225921645-5cf2889a-143c-44a9-a6bc-d03c580b2e90.png alt=img width=100%></div><p>端到端方法汇总如下：</p><div align=center><img src=/img/1715226012910-1e347efb-6bf6-4ac7-b180-a3b09faafa0d.png alt=img width=100%></div><h3 id=217-对话系统评估>2.1.7. 对话系统评估<a hidden class=anchor aria-hidden=true href=#217-对话系统评估>#</a></h3><p>任务式对话整体衡量可以用任务达成率和对话轮次指标，达成率越高越好，用的对话轮次越小越好。每个模块的评估方法如下：</p><div align=center><img src=/img/1715226304994-1f3b8624-a8cc-449f-ab98-5b7f0c7dfdb7.png alt=img width=100%></div><h2 id=22-开放域对话系统>2.2. 开放域对话系统<a hidden class=anchor aria-hidden=true href=#22-开放域对话系统>#</a></h2><p>开放域对话系统旨在与用户进行<strong>无特定任务和领域限制</strong>的闲聊（Ritter等人，2011），通常是完全数据驱动的。开放域对话系统大致可以分为三类：生成式系统(generative systems)、检索式系统(retrieval-based systems)和集成式系统(ensemble systems)。</p><p>生成式系统应用sequence-to-sequence模型，将用户信息和对话历史映射为可能未出现在训练语料库中的响应序列。相比之下，检索式系统尝试从某个确定的响应集中找到一个预先存在的响应。集成式系统结合了生成方法和检索方法，有两种方式：可以将检索到的响应与生成的响应相比较，从中选择最佳者；生成模型也可以用来优化检索到的响应。</p><p>生成式系统能够产生灵活的、与对话上下文相关的响应，但有时它们缺乏连贯性，倾向于生成单调的响应。检索式系统从人类响应集中选取响应，因此能够在表面水平的语言上实现更好的连贯性。然而，检索系统受限于响应集的有限性，有时检索到的响应与对话上下文的相关性较弱。</p><h1 id=3-基于llm的对话系统>3. 基于LLM的对话系统<a hidden class=anchor aria-hidden=true href=#3-基于llm的对话系统>#</a></h1><h2 id=31-基于dl的tod难点>3.1. 基于DL的TOD难点<a hidden class=anchor aria-hidden=true href=#31-基于dl的tod难点>#</a></h2><p>基于深度学习的任务式对话系统有以下几个发展方向：</p><ol><li><strong>低资源启动</strong>。任务型对话系统的成果往往依赖于大量高质量的语料作为训练数据，然而对话数据通常是异构的。例如聊天数据很多，但面向任务的对话数据集非常小。特定领域的对话数据的收集和标注是需要耗费大量的人力。</li><li><strong>域适应能力</strong>。如何以更低的开发成本覆盖更多的领域和场景是任务型对话系统的关键问题之一，快速更新对话 智能体以处理不断变化的环境非常重要。目前的任务型对话系统针对每一个领域都需要手工制定模板导致领域拓展性不足。</li><li><strong>领域知识和常识的引入</strong>。在深度学习框架中融合语言理解能力和推理能力的重要方法是引入领域知识和常识，因为真实人与人之间的交互需要相关领域的知识储备，仅仅依靠对话文本包含的信息无法准确地理解用户输入和恰当地回复用户。而在实际对话中，还需要对信息进行推理并回答，常识知识的引入可以使得对话系统对于用户的话语更深入的理解，从而更贴近真实人类和谐、自然的交互方式。</li></ol><p>以下面的多领域DST为例，需要常识和推理才能正确识别槽位。</p><div align=center><img src=/img/1715164615214-173d9345-e3da-4d4b-a3cc-cf9d1654c4ef.png alt=img width=100%></div><p>而大模型具有<strong>知识</strong>、<strong>推理</strong>、<strong>生成</strong>的能力，并且启动资源低，不需要标注大量对话数据，天然适合建模对话式任务。</p><h2 id=32-基于llm增强的对话系统>3.2. 基于LLM增强的对话系统<a hidden class=anchor aria-hidden=true href=#32-基于llm增强的对话系统>#</a></h2><h3 id=321-整体架构>3.2.1. 整体架构<a hidden class=anchor aria-hidden=true href=#321-整体架构>#</a></h3><p>该架构主要在传统搜推架构的基础上，使用LLM增强其中关键模块。</p><h3 id=322-nlu模块>3.2.2. NLU模块<a hidden class=anchor aria-hidden=true href=#322-nlu模块>#</a></h3><h4 id=3221-直接使用llm>3.2.2.1. 直接使用LLM<a hidden class=anchor aria-hidden=true href=#3221-直接使用llm>#</a></h4><p>意图类别较少时，可以直接使用大模型做意图识别等NLU相关任务。</p><h4 id=3222-llm传统模型>3.2.2.2. LLM+传统模型<a hidden class=anchor aria-hidden=true href=#3222-llm传统模型>#</a></h4><p>当意图类别较多时，可以先使用传统模型召回少量意图，再使用LLM判断最匹配的意图。</p><h4 id=3223-llm蒸馏传统模型>3.2.2.3. LLM蒸馏传统模型<a hidden class=anchor aria-hidden=true href=#3223-llm蒸馏传统模型>#</a></h4><h3 id=323-nlg模块>3.2.3. NLG模块<a hidden class=anchor aria-hidden=true href=#323-nlg模块>#</a></h3><h4 id=3231-利用llm构造faq知识库>3.2.3.1. 利用LLM构造FAQ知识库<a hidden class=anchor aria-hidden=true href=#3231-利用llm构造faq知识库>#</a></h4><p>离线利用LLM构造FAQ知识库，在线通过Q2Q召回QA Pair，将Answer作为结果直接返回给用户</p><h2 id=33-基于llm-agent的对话系统>3.3. 基于LLM Agent的对话系统<a hidden class=anchor aria-hidden=true href=#33-基于llm-agent的对话系统>#</a></h2><h3 id=331-整体架构>3.3.1. 整体架构<a hidden class=anchor aria-hidden=true href=#331-整体架构>#</a></h3><h3 id=332-agent模块>3.3.2. Agent模块<a hidden class=anchor aria-hidden=true href=#332-agent模块>#</a></h3><h4 id=3321-single-agent>3.3.2.1. Single Agent<a hidden class=anchor aria-hidden=true href=#3321-single-agent>#</a></h4><p>类似autoGPT，通过self-ask和react控制对话流程</p><p>显式的对话收敛干预机制</p><h4 id=3322-multi-agent>3.3.2.2. Multi Agent<a hidden class=anchor aria-hidden=true href=#3322-multi-agent>#</a></h4><p>优酷在设计上可分为主持人Agent和角色Agent两类Agent，主持人Agent的主要目的是在全局层面进行对话的管理、决定角色Agent的调用。</p><h3 id=333-rag模块>3.3.3. RAG模块<a hidden class=anchor aria-hidden=true href=#333-rag模块>#</a></h3><h4 id=3331-kv检索>3.3.3.1. KV检索<a hidden class=anchor aria-hidden=true href=#3331-kv检索>#</a></h4><p>构造结构化知识库，通过KV检索相关知识</p><h4 id=3332-q2q检索>3.3.3.2. Q2Q检索<a hidden class=anchor aria-hidden=true href=#3332-q2q检索>#</a></h4><p>对结果的正确性有较高要求的知识，需要先离线构造FAQ知识库，在线时计算Query和Query的相似度，选择相似度最高的QA Pair，将Answer作为知识输入到LLM</p><div align=center><img src=/img/1715247375596-760dcfa4-ad94-445d-9aeb-f345d9c25813.png alt=img width=100%></div><h4 id=3333-q2a检索>3.3.3.3. Q2A检索<a hidden class=anchor aria-hidden=true href=#3333-q2a检索>#</a></h4><p>泛主题、长文本知识（影视剧情、商品详情）可以先划分为多个chunks，在线计算Query和chunk的相似度检索知识</p><h1 id=4-参考文献>4. 参考文献<a hidden class=anchor aria-hidden=true href=#4-参考文献>#</a></h1><ol><li><a href=https://arxiv.org/pdf/2105.04387.pdf>Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey</a></li><li><a href=https://www.csie.ntu.edu.tw/~yvchen/doc/DeepDialogue_Tutorial_ACL.pdf>Deep Learning for Dialogue Systems</a></li><li><a href=http://cjc.ict.ac.cn/online/onlinepaper/zyy-2020925190858.pdf>任务型对话系统研究综述</a></li><li><a href="https://grow.alibaba-inc.com/course/4800010716436517?spm=ata.23639746.0.0.ab8f2470NW7u7x">对话系统技术</a></li><li><a href=https://github.com/gaoisbest/NLP-Projects/blob/master/3_Dialog_system/materials_NLPCC2019/%E9%98%BF%E9%87%8C%E5%B0%8F%E8%9C%9C-%E6%99%BA%E8%83%BD%E4%BA%BA%E6%9C%BA%E4%BA%A4%E4%BA%92%E6%8A%80%E6%9C%AF%E5%AE%9E%E8%B7%B5-0.1-%E6%B5%B7%E9%9D%92.pdf>阿里小蜜技术实践-海青</a></li><li><a href=https://arxiv.org/pdf/1708.05956>An End-to-End Trainable Neural Network Model with Belief Tracking for Task-Oriented Dialog</a></li><li><a href=http://complaw.stanford.edu/readings/eliza.pdf>ELIZA &ndash; A Computer Program For the Study of Natural Language Communication Between Man And Machine</a></li><li><a href=https://arxiv.org/pdf/1606.03777>Neural Belief Tracker: Data-Driven Dialogue State Tracking</a></li><li><a href=https://arxiv.org/pdf/1612.00913>End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager</a></li><li><a href=https://arxiv.org/pdf/1604.04562>A Network-based End-to-End Trainable Task-oriented Dialogue System</a></li></ol></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://hpzhao.github.io/posts/aicon2024-%E5%8C%97%E4%BA%AC/><span class=title>« Prev</span><br><span>AI Con 2024参会总结</span>
</a><a class=next href=https://hpzhao.github.io/posts/%E5%A4%A7%E6%A8%A1%E5%9E%8Bagent/><span class=title>Next »</span><br><span>大模型Agent调研</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://hpzhao.github.io/>Huaipeng's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>